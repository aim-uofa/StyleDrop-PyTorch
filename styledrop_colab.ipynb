{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neild0/StyleDrop-PyTorch-Interactive/blob/main/styledrop_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# StyleDrop Demo\n",
        "\n",
        "<p align=\"left\">\n",
        "  <a href=\"https://huggingface.co/spaces/zideliu/styledrop\"><img alt=\"Huggingface\" src=\"https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-StyleDrop-orange\"></a>\n",
        "  <a href=\"https://replicate.com/cjwbw/styledrop\"><img src=\"https://replicate.com/cjwbw/styledrop/badge\"></a>\n",
        "</p>\n",
        "\n",
        "This is an unofficial PyTorch implementation of [StyleDrop: Text-to-Image Generation in Any Style](https://arxiv.org/abs/2306.00983), based on [zideliu's implementation](https://github.com/zideliu/StyleDrop-PyTorch).\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/zideliu/StyleDrop-PyTorch/main/img/1.png\"/>\n",
        "<img src=\"https://raw.githubusercontent.com/zideliu/StyleDrop-PyTorch/main/img/2.png\"/>\n",
        "<img src=\"https://raw.githubusercontent.com/zideliu/StyleDrop-PyTorch/main/img/5.png\"/>\n"
      ],
      "metadata": {
        "id": "IBNlh6XSHLRq"
      },
      "id": "IBNlh6XSHLRq"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**You need Colab Pro to train this model, with the high-RAM setting on.**"
      ],
      "metadata": {
        "id": "VKEoL0s8IGXr"
      },
      "id": "VKEoL0s8IGXr"
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwU_dnSGIE0o",
        "outputId": "72d3b471-dbc2-453f-f32f-407313b20de7"
      },
      "id": "xwU_dnSGIE0o",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Jul  9 00:53:20 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "pfnc1jJoEMp3"
      },
      "id": "pfnc1jJoEMp3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "546a1e28-bbe1-4cac-832c-090d58aa4b5f",
      "metadata": {
        "id": "546a1e28-bbe1-4cac-832c-090d58aa4b5f"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/neild0/StyleDrop-PyTorch-Interactive\n",
        "!mv StyleDrop-PyTorch-Interactive StyleDrop-PyTorch\n",
        "\n",
        "!pip install omegaconf gdown accelerate==0.12.0 absl-py ml_collections einops wandb ftfy==6.1.1 transformers==4.23.1 loguru webdataset==0.2.5 gradio xformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git lfs install\n",
        "!git clone https://huggingface.co/nzl-thu/MUSE\n",
        "!mv MUSE/assets/* StyleDrop-PyTorch/assets/\n",
        "!rm -rf MUSE"
      ],
      "metadata": {
        "id": "0bpgLXkHcg8v"
      },
      "id": "0bpgLXkHcg8v",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id '13S_unB87n6KKuuMdyMnyExW0G1kplTbP' --output StyleDrop-PyTorch/assets/vqgan_jax_strongaug.ckpt"
      ],
      "metadata": {
        "id": "IJZbaAOVY3_3"
      },
      "id": "IJZbaAOVY3_3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python StyleDrop-PyTorch/extract_empty_feature.py"
      ],
      "metadata": {
        "id": "sVInHq6dbAa0"
      },
      "id": "sVInHq6dbAa0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Set Style"
      ],
      "metadata": {
        "id": "xXcfSxdoHHqa"
      },
      "id": "xXcfSxdoHHqa"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Upload Style File\n",
        "\n",
        "import shutil\n",
        "from google.colab import files\n",
        "import os\n",
        "from IPython.display import Image, display\n",
        "\n",
        "# specify the directory you want to move the file to\n",
        "directory = \"/content/StyleDrop-PyTorch/data\"\n",
        "\n",
        "# get all the files in the directory\n",
        "uploaded = files.upload()\n",
        "\n",
        "if len(uploaded.keys()) != 1:\n",
        "    raise Exception(\"Please only select one file\")\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "\n",
        "    extension = os.path.splitext(fn)[1]\n",
        "\n",
        "    if extension == '.jpg':\n",
        "        # move the file and get the new path\n",
        "        new_path = shutil.move(fn, f\"{directory}/{fn.replace(' ', '_')}\")\n",
        "\n",
        "        # display the image\n",
        "        display(Image(filename=new_path))\n",
        "\n",
        "    else:\n",
        "        raise Exception(\"Please only select jpg files\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "AYqDPmacEWX2"
      },
      "id": "AYqDPmacEWX2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Describe style image\n",
        "\n",
        "object_in_image = \"a house\" #@param {type:\"string\"}\n",
        "style_of_image = \"3d render\" #@param {type:\"string\"}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "-YiFaov_EvHW"
      },
      "id": "-YiFaov_EvHW",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train model"
      ],
      "metadata": {
        "id": "zE9WB5BRF9JM"
      },
      "id": "zE9WB5BRF9JM"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "import glob\n",
        "\n",
        "if 'EVAL_CKPT' in os.environ:\n",
        "    del os.environ['EVAL_CKPT']\n",
        "\n",
        "if 'ADAPTER' in os.environ:\n",
        "    del os.environ['ADAPTER']\n",
        "\n",
        "style_output_folder = style_of_image.replace(\" \", \"_\")\n",
        "\n",
        "os.environ['OUTPUT_DIR'] = style_output_folder\n",
        "\n",
        "!cd StyleDrop-PyTorch && accelerate launch --mixed_precision fp16 train_t2i_colab_v2.py --config=configs/custom.py\n",
        "\n",
        "# get a list of all subdirectories\n",
        "subdirs = glob.glob(f\"/content/StyleDrop-PyTorch/{style_output_folder}/ckpts_II/\" + '*/')\n",
        "subdirs.sort()\n",
        "\n",
        "last_subdir = subdirs[-1]\n",
        "adapter = f\"{last_subdir}{style_output_folder}/adapter.pth\"\n",
        "\n",
        "new_adapter_path = f\"/content/StyleDrop-PyTorch/style_adapter/{style_output_folder}\"\n",
        "os.makedirs(new_adapter_path)\n",
        "os.rename(adapter, f\"{new_adapter_path}/adapter.pth\")\n"
      ],
      "metadata": {
        "id": "epmOxNBY4BbL"
      },
      "id": "epmOxNBY4BbL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run Gradio Interface"
      ],
      "metadata": {
        "id": "XPw0Fs3wHAb6"
      },
      "id": "XPw0Fs3wHAb6"
    },
    {
      "cell_type": "code",
      "source": [
        "!cd StyleDrop-PyTorch && python3 gradio_demo.py"
      ],
      "metadata": {
        "id": "dv3ULWt4wDqH",
        "outputId": "e49a015e-1ee0-4bfd-9673-e2d0b83d105b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "dv3ULWt4wDqH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m2023-07-08 09:15:22.457\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mopen_clip.transformer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m314\u001b[0m - \u001b[34m\u001b[1mxattn in transformer of CLIP is True\u001b[0m\n",
            "\u001b[32m2023-07-08 09:15:37.114\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mopen_clip.transformer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m314\u001b[0m - \u001b[34m\u001b[1mxattn in transformer of CLIP is True\u001b[0m\n",
            "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
            "Strict load\n",
            "Restored from assets/vqgan_jax_strongaug.ckpt\n",
            "xformers available, will use xformers attention\n",
            "\u001b[32m2023-07-08 09:15:56.554\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mlibs.uvit_t2i_vq\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m200\u001b[0m - \u001b[34m\u001b[1mcodebook size in nnet: 1024\u001b[0m\n",
            "num vis tokens: 256\n",
            "\u001b[32m2023-07-08 09:16:03.038\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mlibs.uvit_t2i_vq\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m200\u001b[0m - \u001b[34m\u001b[1mcodebook size in nnet: 1024\u001b[0m\n",
            "num vis tokens: 256\n",
            "\u001b[32m2023-07-08 09:16:09.775\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils\u001b[0m:\u001b[36minitialize_train_state\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1mnnet has 505693313 parameters\u001b[0m\n",
            "\u001b[32m2023-07-08 09:16:10.999\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils\u001b[0m:\u001b[36mresume\u001b[0m:\u001b[36m151\u001b[0m - \u001b[1mresume from assets/ckpts/cc3m-285000.ckpt\u001b[0m\n",
            "\u001b[32m2023-07-08 09:16:10.999\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mload from assets/ckpts/cc3m-285000.ckpt\u001b[0m\n",
            "/content/StyleDrop-PyTorch/gradio_demo.py:197: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.\n",
            "  result_gallery = gr.Gallery(label='Output', show_label=False, elem_id=\"gallery\").style(columns=2, height='auto')\n",
            "Running on local URL:  http://127.0.0.1:7860\n",
            "Running on public URL: https://d75a8f44ab46171d8e.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "Your style\n",
            "load adapter path: style_adapter/style.pth\n",
            "load adapter Done!\n",
            "torch.Size([1, 77, 1280])\n",
            "lambdaA: 2, lambdaB: 5, sample_steps: 36\n",
            "seed: 1234\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
            "torch.Size([1, 3, 256, 256])\n",
            "Your style\n",
            "load adapter path: style_adapter/style.pth\n",
            "load adapter Done!\n",
            "torch.Size([1, 77, 1280])\n",
            "lambdaA: 2, lambdaB: 5, sample_steps: 36\n",
            "seed: 1234\n",
            "torch.Size([1, 3, 256, 256])\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 2125, in block_thread\n",
            "    time.sleep(0.1)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/StyleDrop-PyTorch/gradio_demo.py\", line 243, in <module>\n",
            "    block.launch(share=True,show_error=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 2041, in launch\n",
            "    self.block_thread()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 2127, in block_thread\n",
            "    print(\"Keyboard interruption in main thread... closing server.\")\n",
            "KeyboardInterrupt\n",
            "Killing tunnel 127.0.0.1:7860 <> https://d75a8f44ab46171d8e.gradio.live\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv StyleDrop-PyTorch/style_adapter/286000.ckpt/adapter.pth StyleDrop-PyTorch/style_adapter/style.pth"
      ],
      "metadata": {
        "id": "oGMj3yjTwK-U"
      },
      "id": "oGMj3yjTwK-U",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O4w8j_ZxyIjk"
      },
      "id": "O4w8j_ZxyIjk",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}